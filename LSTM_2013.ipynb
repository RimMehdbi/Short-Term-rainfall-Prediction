{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_2013.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liWm8anLWLBx",
        "outputId": "6fcbd912-e614-448f-c720-8140875de04e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWc9lfDA2MuT",
        "outputId": "a0bc828a-5410-4424-b1f3-8f1879c64d5f"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.0.3-py3-none-any.whl (96 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.34.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.34.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.3 kt-legacy-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD46Ma3XMg8s",
        "outputId": "613dd4cb-05fb-4b9d-8766-a29eabfe9b99"
      },
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"Colab Notebooks/NewApproachExperiments/\"\n",
        "\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Your working directory was changed to /content/drive/My Drive/Colab Notebooks/NewApproachExperiments/\n",
            "\n",
            "An empty text file was created there. You can also run !pwd to confirm the current working directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKNysjF-K6Zy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM , Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import  mean_squared_error, r2_score, mean_absolute_error, max_error\n",
        "import pandas as pd \n",
        "import pandas as pd \n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YfeklBTpAqB",
        "outputId": "d7746e1e-8e65-48fd-c28d-e9b96ea02aa7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHBFFOeCpSvX"
      },
      "source": [
        "# load the dataset\n",
        "dataframe = pandas.read_csv('/content/drive/MyDrive/Rainfallprediction/2013/Percip2013UHL.csv', index_col= 0 , header= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "h2FXmDy1pyM8",
        "outputId": "f53cf160-9151-4929-adb1-3a42c668e69a"
      },
      "source": [
        "# , usecols=[1], engine='python'\n",
        "dataframe= dataframe[ (dataframe['Time_Tag']  > '2013-04-09') & (dataframe['Time_Tag']  < '2013-11-03') ]\n",
        "dataframe.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StationID</th>\n",
              "      <th>Time_Tag</th>\n",
              "      <th>MeasuredValue</th>\n",
              "      <th>MissIndex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HY033</td>\n",
              "      <td>2013-04-09 12:10:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HY033</td>\n",
              "      <td>2013-04-09 12:25:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HY033</td>\n",
              "      <td>2013-04-09 12:40:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HY033</td>\n",
              "      <td>2013-04-09 12:55:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HY033</td>\n",
              "      <td>2013-04-09 13:10:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  StationID             Time_Tag  MeasuredValue  MissIndex\n",
              "1     HY033  2013-04-09 12:10:00            0.0          0\n",
              "2     HY033  2013-04-09 12:25:00            0.0          0\n",
              "3     HY033  2013-04-09 12:40:00            0.0          0\n",
              "4     HY033  2013-04-09 12:55:00            0.0          0\n",
              "5     HY033  2013-04-09 13:10:00            0.0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnp2NzG3e0N2"
      },
      "source": [
        "dataset = dataframe.MeasuredValue\n",
        "dataset = dataset.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZXslREWqMD-",
        "outputId": "53b81ba5-041f-4c2c-aa02-78d3fda2a1bf"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "5        0.0\n",
              "        ... \n",
              "19916    0.0\n",
              "19917    0.0\n",
              "19918    0.0\n",
              "19919    0.0\n",
              "19920    0.0\n",
              "Name: MeasuredValue, Length: 19920, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi4hLjRzfDR4",
        "outputId": "23ac9c63-9472-4261-cf68-d2d4b035872e"
      },
      "source": [
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.7)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size], dataset[train_size:]\n",
        "print(len(train), len(test))#13944"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13944 5976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3kcdOcIrvnb",
        "outputId": "3f458fd1-e92f-499e-f385-8b26a17242b5"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "5        0.0\n",
              "        ... \n",
              "19916    0.0\n",
              "19917    0.0\n",
              "19918    0.0\n",
              "19919    0.0\n",
              "19920    0.0\n",
              "Name: MeasuredValue, Length: 19920, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhQ6dHh7ryIG",
        "outputId": "14d3b43d-a713-4205-aad9-af80e61cf5d1"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "5        0.0\n",
              "        ... \n",
              "13940    0.0\n",
              "13941    0.0\n",
              "13942    0.0\n",
              "13943    0.0\n",
              "13944    0.0\n",
              "Name: MeasuredValue, Length: 13944, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N786DuG3t1LA",
        "outputId": "3e5ed846-4dd1-4eb7-8b45-a6376618bf1d"
      },
      "source": [
        "np.array(train).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3W_kyJWe9Ax"
      },
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)).fit(np.array(train).reshape(-1, 1))\n",
        "train = scaler.transform(np.array(train).reshape(-1, 1))\n",
        "test = scaler.transform(np.array(test).reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hzd-wy6ukR2",
        "outputId": "91c16a39-975d-42f9-8ffc-03c187440966"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13944, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp-6qhOOcozE",
        "outputId": "f2e43d11-0c7d-431f-c531-73549183721d"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5976, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKHyXVPWfJJQ"
      },
      "source": [
        "# Function to create train, test data\n",
        "def create_dataset(dataset, look_back=1 , leadsteps=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-leadsteps):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back + (leadsteps-1) , 0])\n",
        "\treturn np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdRoOk9fN-v"
      },
      "source": [
        "# reshape into X=t and Y=t+1\n",
        "np.random.seed(7)\n",
        "\n",
        "look_back = 10\n",
        "trainX, trainY = create_dataset(train, look_back )\n",
        "testX, testY = create_dataset(test, look_back )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W6EiR_fY3Ip",
        "outputId": "6d63bacf-6b59-4aba-ca17-8f3ef76aeed1"
      },
      "source": [
        "trainY"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7bzUC3BdFt9",
        "outputId": "7a927104-9d70-4f3b-d82c-d379ef300013"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5965, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WojfSDhafR_9"
      },
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1] , 1))\n",
        "testX = np.reshape(testX, (testX.shape[0] , testX.shape[1] , 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEmw7IzhJEqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cd46f8-aafa-47db-8a4c-4348cb9449a2"
      },
      "source": [
        "from kerastuner import HyperModel\n",
        "class LSTMHyperModel(HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "              LSTM(\n",
        "                units=hp.Int('units', 2, 5, 1, default=4),\n",
        "\n",
        "                input_shape=input_shape\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        \n",
        "        model.add(Dense(1,\n",
        "                activation=hp.Choice(\n",
        "                    'dense_activation',\n",
        "                    values=['relu','tanh' 'sigmoid'],\n",
        "                    default='relu')\n",
        "        ))\n",
        "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='mse',metrics=['mse']\n",
        "        )\n",
        "        \n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V1VfHbzJuaw"
      },
      "source": [
        "input_shape = ( look_back , 1)\n",
        "hypermodel = LSTMHyperModel(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Ec6yejJ5bj",
        "outputId": "adf213cf-5d2c-4704-b507-f4241825a917"
      },
      "source": [
        "from kerastuner import BayesianOptimization\n",
        "tuner_bo = BayesianOptimization(\n",
        "            hypermodel,\n",
        "            objective='mse',\n",
        "            max_trials=5,\n",
        "            seed=7,\n",
        "            executions_per_trial=2,\n",
        "            overwrite=True \n",
        "            )\n",
        "tuner_bo.search(trainX, trainY, epochs=200,   batch_size=16,   use_multiprocessing=True  , verbose=2 )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 25m 14s]\n",
            "mse: 0.0002826775162247941\n",
            "\n",
            "Best mse So Far: 0.00025392143288627267\n",
            "Total elapsed time: 02h 07m 38s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF41tdVxQEDz"
      },
      "source": [
        "best_model = tuner_bo.get_best_models(num_models=1)[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agqwhk7bS4TS"
      },
      "source": [
        "best_model.build(trainX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "187HPwG4RX-P"
      },
      "source": [
        "best_hp = tuner_bo.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vC93iUAZ-_J",
        "outputId": "edfe6e34-8ab2-496c-f4fc-57ae8f17cb17"
      },
      "source": [
        "#15 min Model for testing ouliers \n",
        "best_hp.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'sigmoid', 'learning_rate': 0.01, 'units': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9w2bcaCjEn5",
        "outputId": "de24d727-d38e-43b7-b3b6-3d1c8ee2edb9"
      },
      "source": [
        "#15 min \n",
        "best_hp.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'tanh', 'learning_rate': 0.01, 'units': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYMwOC2maWR8",
        "outputId": "f3269a5a-0187-4602-c3b1-ece7460f9690"
      },
      "source": [
        "#30 min \n",
        "best_hp.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'sigmoid', 'learning_rate': 0.01, 'units': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89VOl97Dmj4G",
        "outputId": "f1dcf416-e693-4703-faa9-8884130dc1cd"
      },
      "source": [
        "#45 min \n",
        "best_hp.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'relu', 'learning_rate': 0.01, 'units': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpjkAAbZz6sB",
        "outputId": "fb4c38f3-ac81-477b-801c-2007c7f51185"
      },
      "source": [
        "#60 min \n",
        "best_hp.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'sigmoid', 'learning_rate': 0.01, 'units': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck87diWBcVac"
      },
      "source": [
        "test2Predict = best_model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bmt5VE9O-Qm"
      },
      "source": [
        "def evaluate_model(testY , test2Predict , testshape):\n",
        "  testY = scaler.inverse_transform(testY.reshape((testshape,1)))\n",
        "  test2Predict = scaler.inverse_transform(test2Predict.reshape((testshape,1)))\n",
        "\n",
        "  # Scores on rain and no rain tuples \n",
        "  test = testY[: , 0]\n",
        "  predictions = test2Predict[:,0]\n",
        "  mre_score = max_error (test, predictions)\n",
        "  print('Test MRE: %.3f' % mre_score) \n",
        "  mae_score = mean_absolute_error (test, predictions)\n",
        "  print('Test MAE: %.3f' % mae_score)\n",
        "  rmse_score = np.sqrt(mean_squared_error( test, predictions))\n",
        "  print('Test RMSE: %.3f' % rmse_score)\n",
        "  r2 = r2_score(test, predictions)\n",
        "  print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "  # Scores on rain and no rain tuples \n",
        "  results  = pd.DataFrame( { 'true' :test , 'prediction':predictions } )\n",
        "  print (\"Scores on rain tuples \\n\")\n",
        "\n",
        "  results_true_rain = results[results['true']!=0].true\n",
        "  results_prediction_rain = results[results['true']!=0].prediction\n",
        "  mre_score = max_error ( results_true_rain,results_prediction_rain )\n",
        "  print('Test MRE: %.3f' % mre_score)\n",
        "  mae_score = mean_absolute_error (results_true_rain, results_prediction_rain)\n",
        "  print('Test MAE: %.3f' % mae_score)\n",
        "  rmse_score = np.sqrt(mean_squared_error( results_true_rain, results_prediction_rain))\n",
        "  print('Test RMSE: %.3f' % rmse_score)\n",
        "  r2 = r2_score(results_true_rain, results_prediction_rain)\n",
        "  print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "  print (\"\\n Scores on no-rain tuples \\n\")\n",
        "  results_true_no_rain = results[results['true']==0].true\n",
        "  results_prediction_no_rain = results[results['true']==0].prediction\n",
        "\n",
        "  mre_score = max_error (results_true_no_rain, results_prediction_no_rain)\n",
        "  print('Test MRE: %.3f' % mre_score)\n",
        "  mae_score = mean_absolute_error (results_true_no_rain, results_prediction_no_rain)\n",
        "  print('Test MAE: %.3f' % mae_score)\n",
        "  rmse_score = np.sqrt(mean_squared_error( results_true_no_rain, results_prediction_no_rain))\n",
        "  print('Test RMSE: %.3f' % rmse_score)\n",
        "  r2 = r2_score(results_true_no_rain, results_prediction_no_rain)\n",
        "  print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQImUffdO3j-"
      },
      "source": [
        "Results 15 min data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74ABA-1VWb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0c7f96-8169-4c5c-ba21-26b869deeb96"
      },
      "source": [
        "evaluate_model( testY , test2Predict , testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 8.963\n",
            "Test MAE: 0.035\n",
            "Test RMSE: 0.201\n",
            "Test R2: 0.023\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 8.963\n",
            "Test MAE: 0.505\n",
            "Test RMSE: 0.826\n",
            "Test R2: -0.557\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 0.122\n",
            "Test MAE: 0.005\n",
            "Test RMSE: 0.007\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeE9uY-iO77q"
      },
      "source": [
        "Results 30 min "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARV-cb3O7pO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927bb5c0-e9bb-4aa9-db02-24fcdf64fbe6"
      },
      "source": [
        "evaluate_model( testY , test2Predict ,testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 13.011\n",
            "Test MAE: 0.031\n",
            "Test RMSE: 0.264\n",
            "Test R2: 0.148\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 13.011\n",
            "Test MAE: 0.536\n",
            "Test RMSE: 1.216\n",
            "Test R2: -0.095\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 1.093\n",
            "Test MAE: 0.007\n",
            "Test RMSE: 0.050\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0oknzPZm-NS"
      },
      "source": [
        "Results 45 min "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uevW1Pidm-NT",
        "outputId": "07e8f2f4-3b0e-4442-c6ff-662d5554e582"
      },
      "source": [
        "evaluate_model( testY , test2Predict ,testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 13.200\n",
            "Test MAE: 0.035\n",
            "Test RMSE: 0.273\n",
            "Test R2: 0.087\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 13.200\n",
            "Test MAE: 0.555\n",
            "Test RMSE: 1.247\n",
            "Test R2: -0.152\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 0.974\n",
            "Test MAE: 0.010\n",
            "Test RMSE: 0.065\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80Jj_sx20LVJ"
      },
      "source": [
        "Results 60 min "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mca4cGIO0LVk",
        "outputId": "5429c6eb-bacf-4cc5-b9e0-f651764d5899"
      },
      "source": [
        "evaluate_model( testY , test2Predict ,testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 12.953\n",
            "Test MAE: 0.033\n",
            "Test RMSE: 0.276\n",
            "Test R2: 0.067\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 12.953\n",
            "Test MAE: 0.580\n",
            "Test RMSE: 1.280\n",
            "Test R2: -0.209\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 0.798\n",
            "Test MAE: 0.007\n",
            "Test RMSE: 0.046\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaiLzJS2XCJM"
      },
      "source": [
        "Old version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxhVO04mi7To",
        "outputId": "ac2461db-4a29-454f-a8b9-6cc5ef2cd697"
      },
      "source": [
        "# create and fit the LSTM network\n",
        "\n",
        "#checking reproduciblityy\n",
        "model = Sequential()\n",
        "#model.add(LSTM(3, input_shape=( look_back , 1) , return_sequences=True))\n",
        "#model.add(LSTM(4, input_shape=( look_back , 1) ))\n",
        "#testing 2 layrs\n",
        "#model.add(LSTM(4, input_shape=( look_back , 1) , return_sequences=True))\n",
        "#model.add(LSTM(2, input_shape=( look_back , 1) ))\n",
        "#Back to one layer\n",
        "#model.add(Bidirectional( LSTM(4, input_shape=( look_back , 1))))\n",
        "model.add(LSTM(4, input_shape=( look_back , 1) ))\n",
        "model.add(Dense(1))\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer= 'adam' )\n",
        "history = model.fit(trainX, trainY, epochs= 200  , batch_size=1, verbose=2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "13933/13933 - 41s - loss: 4.3256e-04\n",
            "Epoch 2/200\n",
            "13933/13933 - 24s - loss: 4.0130e-04\n",
            "Epoch 3/200\n",
            "13933/13933 - 24s - loss: 3.9196e-04\n",
            "Epoch 4/200\n",
            "13933/13933 - 24s - loss: 3.8716e-04\n",
            "Epoch 5/200\n",
            "13933/13933 - 25s - loss: 3.7476e-04\n",
            "Epoch 6/200\n",
            "13933/13933 - 25s - loss: 3.8348e-04\n",
            "Epoch 7/200\n",
            "13933/13933 - 25s - loss: 3.6976e-04\n",
            "Epoch 8/200\n",
            "13933/13933 - 25s - loss: 3.7677e-04\n",
            "Epoch 9/200\n",
            "13933/13933 - 24s - loss: 3.8109e-04\n",
            "Epoch 10/200\n",
            "13933/13933 - 25s - loss: 3.7600e-04\n",
            "Epoch 11/200\n",
            "13933/13933 - 25s - loss: 3.7817e-04\n",
            "Epoch 12/200\n",
            "13933/13933 - 24s - loss: 3.7725e-04\n",
            "Epoch 13/200\n",
            "13933/13933 - 25s - loss: 3.8009e-04\n",
            "Epoch 14/200\n",
            "13933/13933 - 24s - loss: 3.7170e-04\n",
            "Epoch 15/200\n",
            "13933/13933 - 24s - loss: 3.7981e-04\n",
            "Epoch 16/200\n",
            "13933/13933 - 24s - loss: 3.7773e-04\n",
            "Epoch 17/200\n",
            "13933/13933 - 24s - loss: 3.7951e-04\n",
            "Epoch 18/200\n",
            "13933/13933 - 24s - loss: 3.7666e-04\n",
            "Epoch 19/200\n",
            "13933/13933 - 24s - loss: 3.7772e-04\n",
            "Epoch 20/200\n",
            "13933/13933 - 24s - loss: 3.7113e-04\n",
            "Epoch 21/200\n",
            "13933/13933 - 25s - loss: 3.8811e-04\n",
            "Epoch 22/200\n",
            "13933/13933 - 24s - loss: 3.8093e-04\n",
            "Epoch 23/200\n",
            "13933/13933 - 25s - loss: 3.7635e-04\n",
            "Epoch 24/200\n",
            "13933/13933 - 24s - loss: 3.8209e-04\n",
            "Epoch 25/200\n",
            "13933/13933 - 25s - loss: 3.7819e-04\n",
            "Epoch 26/200\n",
            "13933/13933 - 24s - loss: 3.8575e-04\n",
            "Epoch 27/200\n",
            "13933/13933 - 25s - loss: 3.6858e-04\n",
            "Epoch 28/200\n",
            "13933/13933 - 25s - loss: 3.6670e-04\n",
            "Epoch 29/200\n",
            "13933/13933 - 24s - loss: 3.7511e-04\n",
            "Epoch 30/200\n",
            "13933/13933 - 24s - loss: 3.7847e-04\n",
            "Epoch 31/200\n",
            "13933/13933 - 25s - loss: 3.6973e-04\n",
            "Epoch 32/200\n",
            "13933/13933 - 24s - loss: 3.6619e-04\n",
            "Epoch 33/200\n",
            "13933/13933 - 24s - loss: 3.7141e-04\n",
            "Epoch 34/200\n",
            "13933/13933 - 24s - loss: 3.5970e-04\n",
            "Epoch 35/200\n",
            "13933/13933 - 25s - loss: 3.6465e-04\n",
            "Epoch 36/200\n",
            "13933/13933 - 24s - loss: 3.6445e-04\n",
            "Epoch 37/200\n",
            "13933/13933 - 24s - loss: 3.5764e-04\n",
            "Epoch 38/200\n",
            "13933/13933 - 24s - loss: 3.7382e-04\n",
            "Epoch 39/200\n",
            "13933/13933 - 24s - loss: 3.7028e-04\n",
            "Epoch 40/200\n",
            "13933/13933 - 24s - loss: 3.4987e-04\n",
            "Epoch 41/200\n",
            "13933/13933 - 24s - loss: 3.7222e-04\n",
            "Epoch 42/200\n",
            "13933/13933 - 24s - loss: 3.5760e-04\n",
            "Epoch 43/200\n",
            "13933/13933 - 24s - loss: 3.5885e-04\n",
            "Epoch 44/200\n",
            "13933/13933 - 24s - loss: 3.6931e-04\n",
            "Epoch 45/200\n",
            "13933/13933 - 24s - loss: 3.5119e-04\n",
            "Epoch 46/200\n",
            "13933/13933 - 24s - loss: 3.6462e-04\n",
            "Epoch 47/200\n",
            "13933/13933 - 25s - loss: 3.7171e-04\n",
            "Epoch 48/200\n",
            "13933/13933 - 25s - loss: 3.7323e-04\n",
            "Epoch 49/200\n",
            "13933/13933 - 24s - loss: 3.6013e-04\n",
            "Epoch 50/200\n",
            "13933/13933 - 25s - loss: 3.5892e-04\n",
            "Epoch 51/200\n",
            "13933/13933 - 24s - loss: 3.6127e-04\n",
            "Epoch 52/200\n",
            "13933/13933 - 25s - loss: 3.6176e-04\n",
            "Epoch 53/200\n",
            "13933/13933 - 24s - loss: 3.4998e-04\n",
            "Epoch 54/200\n",
            "13933/13933 - 24s - loss: 3.4008e-04\n",
            "Epoch 55/200\n",
            "13933/13933 - 24s - loss: 3.5671e-04\n",
            "Epoch 56/200\n",
            "13933/13933 - 24s - loss: 3.5575e-04\n",
            "Epoch 57/200\n",
            "13933/13933 - 25s - loss: 3.4398e-04\n",
            "Epoch 58/200\n",
            "13933/13933 - 24s - loss: 3.4434e-04\n",
            "Epoch 59/200\n",
            "13933/13933 - 24s - loss: 3.4369e-04\n",
            "Epoch 60/200\n",
            "13933/13933 - 24s - loss: 3.4345e-04\n",
            "Epoch 61/200\n",
            "13933/13933 - 24s - loss: 3.3860e-04\n",
            "Epoch 62/200\n",
            "13933/13933 - 25s - loss: 3.3124e-04\n",
            "Epoch 63/200\n",
            "13933/13933 - 24s - loss: 3.3982e-04\n",
            "Epoch 64/200\n",
            "13933/13933 - 24s - loss: 3.2906e-04\n",
            "Epoch 65/200\n",
            "13933/13933 - 25s - loss: 3.3795e-04\n",
            "Epoch 66/200\n",
            "13933/13933 - 24s - loss: 3.3347e-04\n",
            "Epoch 67/200\n",
            "13933/13933 - 24s - loss: 3.3543e-04\n",
            "Epoch 68/200\n",
            "13933/13933 - 24s - loss: 3.3244e-04\n",
            "Epoch 69/200\n",
            "13933/13933 - 24s - loss: 3.3083e-04\n",
            "Epoch 70/200\n",
            "13933/13933 - 24s - loss: 3.3235e-04\n",
            "Epoch 71/200\n",
            "13933/13933 - 24s - loss: 3.3118e-04\n",
            "Epoch 72/200\n",
            "13933/13933 - 24s - loss: 3.2852e-04\n",
            "Epoch 73/200\n",
            "13933/13933 - 24s - loss: 3.3182e-04\n",
            "Epoch 74/200\n",
            "13933/13933 - 24s - loss: 3.3330e-04\n",
            "Epoch 75/200\n",
            "13933/13933 - 24s - loss: 3.3036e-04\n",
            "Epoch 76/200\n",
            "13933/13933 - 24s - loss: 3.3038e-04\n",
            "Epoch 77/200\n",
            "13933/13933 - 24s - loss: 3.3292e-04\n",
            "Epoch 78/200\n",
            "13933/13933 - 24s - loss: 3.3163e-04\n",
            "Epoch 79/200\n",
            "13933/13933 - 24s - loss: 3.2920e-04\n",
            "Epoch 80/200\n",
            "13933/13933 - 25s - loss: 3.2845e-04\n",
            "Epoch 81/200\n",
            "13933/13933 - 24s - loss: 3.2969e-04\n",
            "Epoch 82/200\n",
            "13933/13933 - 24s - loss: 3.2715e-04\n",
            "Epoch 83/200\n",
            "13933/13933 - 24s - loss: 3.2661e-04\n",
            "Epoch 84/200\n",
            "13933/13933 - 25s - loss: 3.2604e-04\n",
            "Epoch 85/200\n",
            "13933/13933 - 24s - loss: 3.2930e-04\n",
            "Epoch 86/200\n",
            "13933/13933 - 24s - loss: 3.2860e-04\n",
            "Epoch 87/200\n",
            "13933/13933 - 24s - loss: 3.3262e-04\n",
            "Epoch 88/200\n",
            "13933/13933 - 24s - loss: 3.2861e-04\n",
            "Epoch 89/200\n",
            "13933/13933 - 24s - loss: 3.2769e-04\n",
            "Epoch 90/200\n",
            "13933/13933 - 24s - loss: 3.3008e-04\n",
            "Epoch 91/200\n",
            "13933/13933 - 24s - loss: 3.2736e-04\n",
            "Epoch 92/200\n",
            "13933/13933 - 24s - loss: 3.2703e-04\n",
            "Epoch 93/200\n",
            "13933/13933 - 24s - loss: 3.3318e-04\n",
            "Epoch 94/200\n",
            "13933/13933 - 24s - loss: 3.2433e-04\n",
            "Epoch 95/200\n",
            "13933/13933 - 24s - loss: 3.2881e-04\n",
            "Epoch 96/200\n",
            "13933/13933 - 24s - loss: 3.3092e-04\n",
            "Epoch 97/200\n",
            "13933/13933 - 24s - loss: 3.2866e-04\n",
            "Epoch 98/200\n",
            "13933/13933 - 24s - loss: 3.2997e-04\n",
            "Epoch 99/200\n",
            "13933/13933 - 24s - loss: 3.3173e-04\n",
            "Epoch 100/200\n",
            "13933/13933 - 24s - loss: 3.2570e-04\n",
            "Epoch 101/200\n",
            "13933/13933 - 24s - loss: 3.2600e-04\n",
            "Epoch 102/200\n",
            "13933/13933 - 24s - loss: 3.2954e-04\n",
            "Epoch 103/200\n",
            "13933/13933 - 24s - loss: 3.2783e-04\n",
            "Epoch 104/200\n",
            "13933/13933 - 24s - loss: 3.2956e-04\n",
            "Epoch 105/200\n",
            "13933/13933 - 24s - loss: 3.2724e-04\n",
            "Epoch 106/200\n",
            "13933/13933 - 24s - loss: 3.2676e-04\n",
            "Epoch 107/200\n",
            "13933/13933 - 24s - loss: 3.2954e-04\n",
            "Epoch 108/200\n",
            "13933/13933 - 24s - loss: 3.2853e-04\n",
            "Epoch 109/200\n",
            "13933/13933 - 25s - loss: 3.3190e-04\n",
            "Epoch 110/200\n",
            "13933/13933 - 26s - loss: 3.2401e-04\n",
            "Epoch 111/200\n",
            "13933/13933 - 25s - loss: 3.3248e-04\n",
            "Epoch 112/200\n",
            "13933/13933 - 25s - loss: 3.2729e-04\n",
            "Epoch 113/200\n",
            "13933/13933 - 24s - loss: 3.2965e-04\n",
            "Epoch 114/200\n",
            "13933/13933 - 24s - loss: 3.2569e-04\n",
            "Epoch 115/200\n",
            "13933/13933 - 25s - loss: 3.3030e-04\n",
            "Epoch 116/200\n",
            "13933/13933 - 25s - loss: 3.2179e-04\n",
            "Epoch 117/200\n",
            "13933/13933 - 24s - loss: 3.3730e-04\n",
            "Epoch 118/200\n",
            "13933/13933 - 24s - loss: 3.2562e-04\n",
            "Epoch 119/200\n",
            "13933/13933 - 24s - loss: 3.2961e-04\n",
            "Epoch 120/200\n",
            "13933/13933 - 24s - loss: 3.2425e-04\n",
            "Epoch 121/200\n",
            "13933/13933 - 24s - loss: 3.2731e-04\n",
            "Epoch 122/200\n",
            "13933/13933 - 24s - loss: 3.2522e-04\n",
            "Epoch 123/200\n",
            "13933/13933 - 25s - loss: 3.2839e-04\n",
            "Epoch 124/200\n",
            "13933/13933 - 25s - loss: 3.2931e-04\n",
            "Epoch 125/200\n",
            "13933/13933 - 24s - loss: 3.2461e-04\n",
            "Epoch 126/200\n",
            "13933/13933 - 24s - loss: 3.3443e-04\n",
            "Epoch 127/200\n",
            "13933/13933 - 24s - loss: 3.2237e-04\n",
            "Epoch 128/200\n",
            "13933/13933 - 24s - loss: 3.2570e-04\n",
            "Epoch 129/200\n",
            "13933/13933 - 24s - loss: 3.2056e-04\n",
            "Epoch 130/200\n",
            "13933/13933 - 24s - loss: 3.2583e-04\n",
            "Epoch 131/200\n",
            "13933/13933 - 24s - loss: 3.2419e-04\n",
            "Epoch 132/200\n",
            "13933/13933 - 24s - loss: 3.2378e-04\n",
            "Epoch 133/200\n",
            "13933/13933 - 24s - loss: 3.2193e-04\n",
            "Epoch 134/200\n",
            "13933/13933 - 24s - loss: 3.2785e-04\n",
            "Epoch 135/200\n",
            "13933/13933 - 24s - loss: 3.2134e-04\n",
            "Epoch 136/200\n",
            "13933/13933 - 25s - loss: 3.3325e-04\n",
            "Epoch 137/200\n",
            "13933/13933 - 25s - loss: 3.1985e-04\n",
            "Epoch 138/200\n",
            "13933/13933 - 25s - loss: 3.2652e-04\n",
            "Epoch 139/200\n",
            "13933/13933 - 25s - loss: 3.2390e-04\n",
            "Epoch 140/200\n",
            "13933/13933 - 24s - loss: 3.2577e-04\n",
            "Epoch 141/200\n",
            "13933/13933 - 24s - loss: 3.2799e-04\n",
            "Epoch 142/200\n",
            "13933/13933 - 24s - loss: 3.2348e-04\n",
            "Epoch 143/200\n",
            "13933/13933 - 24s - loss: 3.2243e-04\n",
            "Epoch 144/200\n",
            "13933/13933 - 24s - loss: 3.2642e-04\n",
            "Epoch 145/200\n",
            "13933/13933 - 24s - loss: 3.2125e-04\n",
            "Epoch 146/200\n",
            "13933/13933 - 24s - loss: 3.2670e-04\n",
            "Epoch 147/200\n",
            "13933/13933 - 24s - loss: 3.2482e-04\n",
            "Epoch 148/200\n",
            "13933/13933 - 24s - loss: 3.2172e-04\n",
            "Epoch 149/200\n",
            "13933/13933 - 24s - loss: 3.2224e-04\n",
            "Epoch 150/200\n",
            "13933/13933 - 24s - loss: 3.1943e-04\n",
            "Epoch 151/200\n",
            "13933/13933 - 24s - loss: 3.2259e-04\n",
            "Epoch 152/200\n",
            "13933/13933 - 24s - loss: 3.2341e-04\n",
            "Epoch 153/200\n",
            "13933/13933 - 24s - loss: 3.2261e-04\n",
            "Epoch 154/200\n",
            "13933/13933 - 24s - loss: 3.2019e-04\n",
            "Epoch 155/200\n",
            "13933/13933 - 24s - loss: 3.2435e-04\n",
            "Epoch 156/200\n",
            "13933/13933 - 24s - loss: 3.3242e-04\n",
            "Epoch 157/200\n",
            "13933/13933 - 24s - loss: 3.2299e-04\n",
            "Epoch 158/200\n",
            "13933/13933 - 25s - loss: 3.2067e-04\n",
            "Epoch 159/200\n",
            "13933/13933 - 24s - loss: 3.2249e-04\n",
            "Epoch 160/200\n",
            "13933/13933 - 24s - loss: 3.1631e-04\n",
            "Epoch 161/200\n",
            "13933/13933 - 25s - loss: 3.2855e-04\n",
            "Epoch 162/200\n",
            "13933/13933 - 25s - loss: 3.1940e-04\n",
            "Epoch 163/200\n",
            "13933/13933 - 25s - loss: 3.2483e-04\n",
            "Epoch 164/200\n",
            "13933/13933 - 24s - loss: 3.1942e-04\n",
            "Epoch 165/200\n",
            "13933/13933 - 24s - loss: 3.2477e-04\n",
            "Epoch 166/200\n",
            "13933/13933 - 24s - loss: 3.2317e-04\n",
            "Epoch 167/200\n",
            "13933/13933 - 24s - loss: 3.2596e-04\n",
            "Epoch 168/200\n",
            "13933/13933 - 24s - loss: 3.2063e-04\n",
            "Epoch 169/200\n",
            "13933/13933 - 24s - loss: 3.2612e-04\n",
            "Epoch 170/200\n",
            "13933/13933 - 24s - loss: 3.1885e-04\n",
            "Epoch 171/200\n",
            "13933/13933 - 24s - loss: 3.2121e-04\n",
            "Epoch 172/200\n",
            "13933/13933 - 24s - loss: 3.2378e-04\n",
            "Epoch 173/200\n",
            "13933/13933 - 24s - loss: 3.1713e-04\n",
            "Epoch 174/200\n",
            "13933/13933 - 24s - loss: 3.1935e-04\n",
            "Epoch 175/200\n",
            "13933/13933 - 24s - loss: 3.2049e-04\n",
            "Epoch 176/200\n",
            "13933/13933 - 24s - loss: 3.1418e-04\n",
            "Epoch 177/200\n",
            "13933/13933 - 24s - loss: 3.1962e-04\n",
            "Epoch 178/200\n",
            "13933/13933 - 24s - loss: 3.2329e-04\n",
            "Epoch 179/200\n",
            "13933/13933 - 24s - loss: 3.2104e-04\n",
            "Epoch 180/200\n",
            "13933/13933 - 24s - loss: 3.2289e-04\n",
            "Epoch 181/200\n",
            "13933/13933 - 24s - loss: 3.2060e-04\n",
            "Epoch 182/200\n",
            "13933/13933 - 24s - loss: 3.2143e-04\n",
            "Epoch 183/200\n",
            "13933/13933 - 24s - loss: 3.1967e-04\n",
            "Epoch 184/200\n",
            "13933/13933 - 24s - loss: 3.2222e-04\n",
            "Epoch 185/200\n",
            "13933/13933 - 24s - loss: 3.2320e-04\n",
            "Epoch 186/200\n",
            "13933/13933 - 24s - loss: 3.2269e-04\n",
            "Epoch 187/200\n",
            "13933/13933 - 24s - loss: 3.2065e-04\n",
            "Epoch 188/200\n",
            "13933/13933 - 24s - loss: 3.2578e-04\n",
            "Epoch 189/200\n",
            "13933/13933 - 24s - loss: 3.1915e-04\n",
            "Epoch 190/200\n",
            "13933/13933 - 24s - loss: 3.2551e-04\n",
            "Epoch 191/200\n",
            "13933/13933 - 24s - loss: 3.2141e-04\n",
            "Epoch 192/200\n",
            "13933/13933 - 24s - loss: 3.2568e-04\n",
            "Epoch 193/200\n",
            "13933/13933 - 24s - loss: 3.1926e-04\n",
            "Epoch 194/200\n",
            "13933/13933 - 24s - loss: 3.2116e-04\n",
            "Epoch 195/200\n",
            "13933/13933 - 24s - loss: 3.2154e-04\n",
            "Epoch 196/200\n",
            "13933/13933 - 24s - loss: 3.2053e-04\n",
            "Epoch 197/200\n",
            "13933/13933 - 24s - loss: 3.2085e-04\n",
            "Epoch 198/200\n",
            "13933/13933 - 25s - loss: 3.2239e-04\n",
            "Epoch 199/200\n",
            "13933/13933 - 25s - loss: 3.2189e-04\n",
            "Epoch 200/200\n",
            "13933/13933 - 24s - loss: 3.2618e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxIl1iD2fXsO",
        "outputId": "534b0a30-84ea-4408-a53d-a5e1d880de2c"
      },
      "source": [
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "#model.add(LSTM(3, input_shape=( look_back , 1) , return_sequences=True))\n",
        "#model.add(LSTM(4, input_shape=( look_back , 1) ))\n",
        "#testing 2 layrs\n",
        "#model.add(LSTM(4, input_shape=( look_back , 1) , return_sequences=True))\n",
        "#model.add(LSTM(2, input_shape=( look_back , 1) ))\n",
        "#Back to one layer\n",
        "#model.add(Bidirectional( LSTM(4, input_shape=( look_back , 1))))\n",
        "model.add(LSTM(4, input_shape=( look_back , 1) ))\n",
        "model.add(Dense(1))\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer= 'adam' )\n",
        "history = model.fit(trainX, trainY, epochs= 200  , batch_size=1, verbose=2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "13933/13933 - 57s - loss: 4.2588e-04\n",
            "Epoch 2/200\n",
            "13933/13933 - 35s - loss: 4.0187e-04\n",
            "Epoch 3/200\n",
            "13933/13933 - 35s - loss: 3.8207e-04\n",
            "Epoch 4/200\n",
            "13933/13933 - 35s - loss: 3.8832e-04\n",
            "Epoch 5/200\n",
            "13933/13933 - 35s - loss: 3.8315e-04\n",
            "Epoch 6/200\n",
            "13933/13933 - 35s - loss: 3.8688e-04\n",
            "Epoch 7/200\n",
            "13933/13933 - 35s - loss: 3.8206e-04\n",
            "Epoch 8/200\n",
            "13933/13933 - 35s - loss: 3.8339e-04\n",
            "Epoch 9/200\n",
            "13933/13933 - 35s - loss: 3.7729e-04\n",
            "Epoch 10/200\n",
            "13933/13933 - 35s - loss: 3.8242e-04\n",
            "Epoch 11/200\n",
            "13933/13933 - 35s - loss: 3.8017e-04\n",
            "Epoch 12/200\n",
            "13933/13933 - 35s - loss: 3.8186e-04\n",
            "Epoch 13/200\n",
            "13933/13933 - 35s - loss: 3.8157e-04\n",
            "Epoch 14/200\n",
            "13933/13933 - 35s - loss: 3.7720e-04\n",
            "Epoch 15/200\n",
            "13933/13933 - 35s - loss: 3.8094e-04\n",
            "Epoch 16/200\n",
            "13933/13933 - 35s - loss: 3.7012e-04\n",
            "Epoch 17/200\n",
            "13933/13933 - 35s - loss: 3.8115e-04\n",
            "Epoch 18/200\n",
            "13933/13933 - 35s - loss: 3.7223e-04\n",
            "Epoch 19/200\n",
            "13933/13933 - 35s - loss: 3.7438e-04\n",
            "Epoch 20/200\n",
            "13933/13933 - 35s - loss: 3.7836e-04\n",
            "Epoch 21/200\n",
            "13933/13933 - 35s - loss: 3.6675e-04\n",
            "Epoch 22/200\n",
            "13933/13933 - 35s - loss: 3.7981e-04\n",
            "Epoch 23/200\n",
            "13933/13933 - 35s - loss: 3.8099e-04\n",
            "Epoch 24/200\n",
            "13933/13933 - 35s - loss: 3.6874e-04\n",
            "Epoch 25/200\n",
            "13933/13933 - 34s - loss: 3.7930e-04\n",
            "Epoch 26/200\n",
            "13933/13933 - 34s - loss: 3.7160e-04\n",
            "Epoch 27/200\n",
            "13933/13933 - 34s - loss: 3.8232e-04\n",
            "Epoch 28/200\n",
            "13933/13933 - 34s - loss: 3.7635e-04\n",
            "Epoch 29/200\n",
            "13933/13933 - 34s - loss: 3.6697e-04\n",
            "Epoch 30/200\n",
            "13933/13933 - 34s - loss: 3.7061e-04\n",
            "Epoch 31/200\n",
            "13933/13933 - 34s - loss: 3.6725e-04\n",
            "Epoch 32/200\n",
            "13933/13933 - 34s - loss: 3.7064e-04\n",
            "Epoch 33/200\n",
            "13933/13933 - 35s - loss: 3.6254e-04\n",
            "Epoch 34/200\n",
            "13933/13933 - 34s - loss: 3.5668e-04\n",
            "Epoch 35/200\n",
            "13933/13933 - 34s - loss: 3.6677e-04\n",
            "Epoch 36/200\n",
            "13933/13933 - 34s - loss: 3.4913e-04\n",
            "Epoch 37/200\n",
            "13933/13933 - 34s - loss: 3.5663e-04\n",
            "Epoch 38/200\n",
            "13933/13933 - 34s - loss: 3.4818e-04\n",
            "Epoch 39/200\n",
            "13933/13933 - 34s - loss: 3.5277e-04\n",
            "Epoch 40/200\n",
            "13933/13933 - 34s - loss: 3.4145e-04\n",
            "Epoch 41/200\n",
            "13933/13933 - 34s - loss: 3.5275e-04\n",
            "Epoch 42/200\n",
            "13933/13933 - 34s - loss: 3.5905e-04\n",
            "Epoch 43/200\n",
            "13933/13933 - 34s - loss: 3.6501e-04\n",
            "Epoch 44/200\n",
            "13933/13933 - 34s - loss: 3.6338e-04\n",
            "Epoch 45/200\n",
            "13933/13933 - 34s - loss: 3.5110e-04\n",
            "Epoch 46/200\n",
            "13933/13933 - 35s - loss: 3.6372e-04\n",
            "Epoch 47/200\n",
            "13933/13933 - 34s - loss: 3.4908e-04\n",
            "Epoch 48/200\n",
            "13933/13933 - 34s - loss: 3.5285e-04\n",
            "Epoch 49/200\n",
            "13933/13933 - 34s - loss: 3.6420e-04\n",
            "Epoch 50/200\n",
            "13933/13933 - 35s - loss: 3.4488e-04\n",
            "Epoch 51/200\n",
            "13933/13933 - 35s - loss: 3.5110e-04\n",
            "Epoch 52/200\n",
            "13933/13933 - 35s - loss: 3.5195e-04\n",
            "Epoch 53/200\n",
            "13933/13933 - 35s - loss: 3.5156e-04\n",
            "Epoch 54/200\n",
            "13933/13933 - 34s - loss: 3.5084e-04\n",
            "Epoch 55/200\n",
            "13933/13933 - 34s - loss: 3.5999e-04\n",
            "Epoch 56/200\n",
            "13933/13933 - 34s - loss: 3.5162e-04\n",
            "Epoch 57/200\n",
            "13933/13933 - 34s - loss: 3.6033e-04\n",
            "Epoch 58/200\n",
            "13933/13933 - 34s - loss: 3.6050e-04\n",
            "Epoch 59/200\n",
            "13933/13933 - 35s - loss: 3.7950e-04\n",
            "Epoch 60/200\n",
            "13933/13933 - 35s - loss: 3.7877e-04\n",
            "Epoch 61/200\n",
            "13933/13933 - 35s - loss: 3.6699e-04\n",
            "Epoch 62/200\n",
            "13933/13933 - 35s - loss: 3.7678e-04\n",
            "Epoch 63/200\n",
            "13933/13933 - 35s - loss: 3.7012e-04\n",
            "Epoch 64/200\n",
            "13933/13933 - 34s - loss: 3.8323e-04\n",
            "Epoch 65/200\n",
            "13933/13933 - 34s - loss: 3.7964e-04\n",
            "Epoch 66/200\n",
            "13933/13933 - 34s - loss: 3.6590e-04\n",
            "Epoch 67/200\n",
            "13933/13933 - 35s - loss: 3.6741e-04\n",
            "Epoch 68/200\n",
            "13933/13933 - 34s - loss: 3.7475e-04\n",
            "Epoch 69/200\n",
            "13933/13933 - 35s - loss: 3.6741e-04\n",
            "Epoch 70/200\n",
            "13933/13933 - 35s - loss: 3.6986e-04\n",
            "Epoch 71/200\n",
            "13933/13933 - 35s - loss: 3.6772e-04\n",
            "Epoch 72/200\n",
            "13933/13933 - 35s - loss: 3.5252e-04\n",
            "Epoch 73/200\n",
            "13933/13933 - 35s - loss: 3.4647e-04\n",
            "Epoch 74/200\n",
            "13933/13933 - 34s - loss: 3.7028e-04\n",
            "Epoch 75/200\n",
            "13933/13933 - 34s - loss: 3.7237e-04\n",
            "Epoch 76/200\n",
            "13933/13933 - 34s - loss: 3.6816e-04\n",
            "Epoch 77/200\n",
            "13933/13933 - 34s - loss: 3.6723e-04\n",
            "Epoch 78/200\n",
            "13933/13933 - 35s - loss: 3.7019e-04\n",
            "Epoch 79/200\n",
            "13933/13933 - 34s - loss: 3.5667e-04\n",
            "Epoch 80/200\n",
            "13933/13933 - 35s - loss: 3.3439e-04\n",
            "Epoch 81/200\n",
            "13933/13933 - 34s - loss: 3.6901e-04\n",
            "Epoch 82/200\n",
            "13933/13933 - 34s - loss: 3.4634e-04\n",
            "Epoch 83/200\n",
            "13933/13933 - 35s - loss: 3.7069e-04\n",
            "Epoch 84/200\n",
            "13933/13933 - 35s - loss: 3.6717e-04\n",
            "Epoch 85/200\n",
            "13933/13933 - 34s - loss: 3.6769e-04\n",
            "Epoch 86/200\n",
            "13933/13933 - 34s - loss: 3.5974e-04\n",
            "Epoch 87/200\n",
            "13933/13933 - 35s - loss: 3.5645e-04\n",
            "Epoch 88/200\n",
            "13933/13933 - 34s - loss: 3.6225e-04\n",
            "Epoch 89/200\n",
            "13933/13933 - 35s - loss: 3.4923e-04\n",
            "Epoch 90/200\n",
            "13933/13933 - 35s - loss: 3.5908e-04\n",
            "Epoch 91/200\n",
            "13933/13933 - 35s - loss: 3.7037e-04\n",
            "Epoch 92/200\n",
            "13933/13933 - 35s - loss: 3.5626e-04\n",
            "Epoch 93/200\n",
            "13933/13933 - 35s - loss: 3.5190e-04\n",
            "Epoch 94/200\n",
            "13933/13933 - 35s - loss: 3.5796e-04\n",
            "Epoch 95/200\n",
            "13933/13933 - 35s - loss: 3.5346e-04\n",
            "Epoch 96/200\n",
            "13933/13933 - 35s - loss: 3.4790e-04\n",
            "Epoch 97/200\n",
            "13933/13933 - 35s - loss: 3.4165e-04\n",
            "Epoch 98/200\n",
            "13933/13933 - 35s - loss: 3.4635e-04\n",
            "Epoch 99/200\n",
            "13933/13933 - 35s - loss: 3.3781e-04\n",
            "Epoch 100/200\n",
            "13933/13933 - 35s - loss: 3.7345e-04\n",
            "Epoch 101/200\n",
            "13933/13933 - 35s - loss: 3.6743e-04\n",
            "Epoch 102/200\n",
            "13933/13933 - 35s - loss: 3.2883e-04\n",
            "Epoch 103/200\n",
            "13933/13933 - 35s - loss: 3.3197e-04\n",
            "Epoch 104/200\n",
            "13933/13933 - 34s - loss: 3.5679e-04\n",
            "Epoch 105/200\n",
            "13933/13933 - 35s - loss: 3.3507e-04\n",
            "Epoch 106/200\n",
            "13933/13933 - 35s - loss: 3.5987e-04\n",
            "Epoch 107/200\n",
            "13933/13933 - 35s - loss: 3.7177e-04\n",
            "Epoch 108/200\n",
            "13933/13933 - 35s - loss: 3.3955e-04\n",
            "Epoch 109/200\n",
            "13933/13933 - 35s - loss: 3.6139e-04\n",
            "Epoch 110/200\n",
            "13933/13933 - 35s - loss: 3.6182e-04\n",
            "Epoch 111/200\n",
            "13933/13933 - 35s - loss: 3.4793e-04\n",
            "Epoch 112/200\n",
            "13933/13933 - 35s - loss: 3.6577e-04\n",
            "Epoch 113/200\n",
            "13933/13933 - 35s - loss: 3.5592e-04\n",
            "Epoch 114/200\n",
            "13933/13933 - 35s - loss: 3.5130e-04\n",
            "Epoch 115/200\n",
            "13933/13933 - 35s - loss: 3.5512e-04\n",
            "Epoch 116/200\n",
            "13933/13933 - 35s - loss: 3.3931e-04\n",
            "Epoch 117/200\n",
            "13933/13933 - 35s - loss: 3.6424e-04\n",
            "Epoch 118/200\n",
            "13933/13933 - 34s - loss: 3.6652e-04\n",
            "Epoch 119/200\n",
            "13933/13933 - 34s - loss: 3.6853e-04\n",
            "Epoch 120/200\n",
            "13933/13933 - 34s - loss: 3.4949e-04\n",
            "Epoch 121/200\n",
            "13933/13933 - 35s - loss: 3.6196e-04\n",
            "Epoch 122/200\n",
            "13933/13933 - 34s - loss: 3.2803e-04\n",
            "Epoch 123/200\n",
            "13933/13933 - 35s - loss: 3.6581e-04\n",
            "Epoch 124/200\n",
            "13933/13933 - 34s - loss: 3.7406e-04\n",
            "Epoch 125/200\n",
            "13933/13933 - 35s - loss: 3.7239e-04\n",
            "Epoch 126/200\n",
            "13933/13933 - 35s - loss: 3.6702e-04\n",
            "Epoch 127/200\n",
            "13933/13933 - 35s - loss: 3.5877e-04\n",
            "Epoch 128/200\n",
            "13933/13933 - 35s - loss: 3.6388e-04\n",
            "Epoch 129/200\n",
            "13933/13933 - 34s - loss: 3.6244e-04\n",
            "Epoch 130/200\n",
            "13933/13933 - 35s - loss: 3.3526e-04\n",
            "Epoch 131/200\n",
            "13933/13933 - 35s - loss: 3.7055e-04\n",
            "Epoch 132/200\n",
            "13933/13933 - 35s - loss: 3.6220e-04\n",
            "Epoch 133/200\n",
            "13933/13933 - 35s - loss: 3.6361e-04\n",
            "Epoch 134/200\n",
            "13933/13933 - 35s - loss: 3.5906e-04\n",
            "Epoch 135/200\n",
            "13933/13933 - 35s - loss: 3.6320e-04\n",
            "Epoch 136/200\n",
            "13933/13933 - 35s - loss: 3.6258e-04\n",
            "Epoch 137/200\n",
            "13933/13933 - 34s - loss: 3.3200e-04\n",
            "Epoch 138/200\n",
            "13933/13933 - 35s - loss: 3.4680e-04\n",
            "Epoch 139/200\n",
            "13933/13933 - 35s - loss: 3.5842e-04\n",
            "Epoch 140/200\n",
            "13933/13933 - 35s - loss: 3.5180e-04\n",
            "Epoch 141/200\n",
            "13933/13933 - 35s - loss: 3.4984e-04\n",
            "Epoch 142/200\n",
            "13933/13933 - 35s - loss: 3.4521e-04\n",
            "Epoch 143/200\n",
            "13933/13933 - 35s - loss: 3.6007e-04\n",
            "Epoch 144/200\n",
            "13933/13933 - 35s - loss: 3.4739e-04\n",
            "Epoch 145/200\n",
            "13933/13933 - 35s - loss: 3.4904e-04\n",
            "Epoch 146/200\n",
            "13933/13933 - 35s - loss: 3.2636e-04\n",
            "Epoch 147/200\n",
            "13933/13933 - 35s - loss: 3.5585e-04\n",
            "Epoch 148/200\n",
            "13933/13933 - 35s - loss: 3.4519e-04\n",
            "Epoch 149/200\n",
            "13933/13933 - 35s - loss: 3.5174e-04\n",
            "Epoch 150/200\n",
            "13933/13933 - 35s - loss: 3.4495e-04\n",
            "Epoch 151/200\n",
            "13933/13933 - 35s - loss: 3.5622e-04\n",
            "Epoch 152/200\n",
            "13933/13933 - 35s - loss: 3.5546e-04\n",
            "Epoch 153/200\n",
            "13933/13933 - 35s - loss: 3.3891e-04\n",
            "Epoch 154/200\n",
            "13933/13933 - 34s - loss: 3.4685e-04\n",
            "Epoch 155/200\n",
            "13933/13933 - 34s - loss: 3.4470e-04\n",
            "Epoch 156/200\n",
            "13933/13933 - 35s - loss: 3.3606e-04\n",
            "Epoch 157/200\n",
            "13933/13933 - 35s - loss: 3.3993e-04\n",
            "Epoch 158/200\n",
            "13933/13933 - 35s - loss: 3.3574e-04\n",
            "Epoch 159/200\n",
            "13933/13933 - 35s - loss: 3.3708e-04\n",
            "Epoch 160/200\n",
            "13933/13933 - 35s - loss: 3.1374e-04\n",
            "Epoch 161/200\n",
            "13933/13933 - 34s - loss: 3.4000e-04\n",
            "Epoch 162/200\n",
            "13933/13933 - 35s - loss: 3.4469e-04\n",
            "Epoch 163/200\n",
            "13933/13933 - 35s - loss: 3.3068e-04\n",
            "Epoch 164/200\n",
            "13933/13933 - 35s - loss: 3.3977e-04\n",
            "Epoch 165/200\n",
            "13933/13933 - 35s - loss: 3.3608e-04\n",
            "Epoch 166/200\n",
            "13933/13933 - 35s - loss: 3.3485e-04\n",
            "Epoch 167/200\n",
            "13933/13933 - 34s - loss: 3.3331e-04\n",
            "Epoch 168/200\n",
            "13933/13933 - 35s - loss: 3.4236e-04\n",
            "Epoch 169/200\n",
            "13933/13933 - 35s - loss: 3.3954e-04\n",
            "Epoch 170/200\n",
            "13933/13933 - 35s - loss: 3.2572e-04\n",
            "Epoch 171/200\n",
            "13933/13933 - 34s - loss: 3.3719e-04\n",
            "Epoch 172/200\n",
            "13933/13933 - 35s - loss: 3.3127e-04\n",
            "Epoch 173/200\n",
            "13933/13933 - 35s - loss: 3.2471e-04\n",
            "Epoch 174/200\n",
            "13933/13933 - 35s - loss: 3.2258e-04\n",
            "Epoch 175/200\n",
            "13933/13933 - 35s - loss: 3.2580e-04\n",
            "Epoch 176/200\n",
            "13933/13933 - 35s - loss: 3.3218e-04\n",
            "Epoch 177/200\n",
            "13933/13933 - 35s - loss: 3.1922e-04\n",
            "Epoch 178/200\n",
            "13933/13933 - 35s - loss: 3.3259e-04\n",
            "Epoch 179/200\n",
            "13933/13933 - 35s - loss: 3.2482e-04\n",
            "Epoch 180/200\n",
            "13933/13933 - 35s - loss: 3.2236e-04\n",
            "Epoch 181/200\n",
            "13933/13933 - 35s - loss: 3.4233e-04\n",
            "Epoch 182/200\n",
            "13933/13933 - 35s - loss: 3.2142e-04\n",
            "Epoch 183/200\n",
            "13933/13933 - 35s - loss: 3.3058e-04\n",
            "Epoch 184/200\n",
            "13933/13933 - 35s - loss: 3.2456e-04\n",
            "Epoch 185/200\n",
            "13933/13933 - 35s - loss: 3.3134e-04\n",
            "Epoch 186/200\n",
            "13933/13933 - 35s - loss: 3.2275e-04\n",
            "Epoch 187/200\n",
            "13933/13933 - 35s - loss: 3.3136e-04\n",
            "Epoch 188/200\n",
            "13933/13933 - 35s - loss: 3.3673e-04\n",
            "Epoch 189/200\n",
            "13933/13933 - 35s - loss: 3.2427e-04\n",
            "Epoch 190/200\n",
            "13933/13933 - 35s - loss: 3.2150e-04\n",
            "Epoch 191/200\n",
            "13933/13933 - 35s - loss: 3.2831e-04\n",
            "Epoch 192/200\n",
            "13933/13933 - 35s - loss: 3.3281e-04\n",
            "Epoch 193/200\n",
            "13933/13933 - 35s - loss: 3.2101e-04\n",
            "Epoch 194/200\n",
            "13933/13933 - 35s - loss: 3.2452e-04\n",
            "Epoch 195/200\n",
            "13933/13933 - 35s - loss: 3.2274e-04\n",
            "Epoch 196/200\n",
            "13933/13933 - 35s - loss: 3.2549e-04\n",
            "Epoch 197/200\n",
            "13933/13933 - 35s - loss: 3.3533e-04\n",
            "Epoch 198/200\n",
            "13933/13933 - 35s - loss: 3.1820e-04\n",
            "Epoch 199/200\n",
            "13933/13933 - 35s - loss: 3.2772e-04\n",
            "Epoch 200/200\n",
            "13933/13933 - 35s - loss: 3.2847e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVA486M9Xikv",
        "outputId": "6ce7a87c-a7b9-47eb-dc21-2bc26f6905da"
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13933,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu-XcRsukh_n",
        "outputId": "d4173637-c3b6-4154-cda8-fd514c9deaae"
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5965,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVvTMLfIMjou",
        "outputId": "0bd562b5-f071-405f-8e58-ee5162df15c8"
      },
      "source": [
        "# make predictions new \n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(trainY.reshape((13933, 1)))\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(testY.reshape((5965,1)))\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[: , 0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY[: , 0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 0.31 RMSE\n",
            "Test Score: 0.18 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSnu5sEM9PV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zNVnr_kkmp_",
        "outputId": "1f2393a7-b958-47be-c2da-132dda8d3e5e"
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5971,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChgvcMAEfffW",
        "outputId": "a04292af-b245-4428-ecaf-9b1bd2a806f2"
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(trainY.reshape((13933, 1)))\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(testY.reshape((5965,1)))\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[: , 0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY[: , 0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 0.30 RMSE\n",
            "Test Score: 0.17 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTeLW9VcNPnr",
        "outputId": "fec52179-1c90-4b74-a707-92b9204612bd"
      },
      "source": [
        "\n",
        "# Scores on rain and no rain tuples seperately \n",
        "test = testY[: , 0]\n",
        "predictions = testPredict[:,0]\n",
        "mre_score = max_error (test, predictions)\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (test, predictions)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( test, predictions))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(test, predictions)\n",
        "print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "results  = pd.DataFrame( { 'true' :test , 'prediction':predictions } )\n",
        "print (\"Scores on rain tuples \\n\")\n",
        "\n",
        "results_true_rain = results[results['true']!=0].true\n",
        "results_prediction_rain = results[results['true']!=0].prediction\n",
        "mre_score = max_error ( results_true_rain,results_prediction_rain )\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (results_true_rain, results_prediction_rain)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( results_true_rain, results_prediction_rain))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(results_true_rain, results_prediction_rain)\n",
        "print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "print (\"\\n Scores on no-rain tuples \\n\")\n",
        "results_true_no_rain = results[results['true']==0].true\n",
        "results_prediction_no_rain = results[results['true']==0].prediction\n",
        "\n",
        "mre_score = max_error (results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( results_true_no_rain, results_prediction_no_rain))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test R2: %.3f' % r2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 8.399\n",
            "Test MAE: 0.032\n",
            "Test RMSE: 0.180\n",
            "Test R2: 0.218\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 8.399\n",
            "Test MAE: 0.383\n",
            "Test RMSE: 0.707\n",
            "Test R2: -0.139\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 1.141\n",
            "Test MAE: 0.010\n",
            "Test RMSE: 0.055\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXCdByCQYmRR"
      },
      "source": [
        "Analysing errors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6t0w-Z_Pl_2"
      },
      "source": [
        "#Analysis of performance on Test data \n",
        "y = testY[: , 0]\n",
        "y_hat = testPredict[: , 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8silsJlRRuFJ"
      },
      "source": [
        "y_y_hat = pd.DataFrame({'y':y , 'y_hat':y_hat} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6TZb9RDSYj_"
      },
      "source": [
        "pd.set_option('display.max_rows', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EUCNhZkZSXb",
        "outputId": "0564d3ea-c9bf-428f-f9fa-b05108056307"
      },
      "source": [
        "for i in range (1,90):\n",
        "  print (y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.2\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5u4rCwEZSHu6",
        "outputId": "e5ff62a8-b1ff-480d-9a7c-159ff21a07f8"
      },
      "source": [
        "y_y_hat.iloc[1:99]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.008020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.003469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.165393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.031376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      y     y_hat\n",
              "1   0.0  0.101148\n",
              "2   0.0  0.102440\n",
              "3   0.0  0.023606\n",
              "4   0.0  0.004690\n",
              "5   0.0  0.018087\n",
              "6   0.0 -0.008020\n",
              "7   0.0 -0.003469\n",
              "8   0.0 -0.005368\n",
              "9   0.0 -0.007191\n",
              "10  0.0 -0.007010\n",
              "11  0.0 -0.007010\n",
              "12  0.0 -0.007010\n",
              "13  0.0 -0.007010\n",
              "14  0.0 -0.007010\n",
              "15  0.0 -0.007010\n",
              "16  0.0 -0.007010\n",
              "17  0.0 -0.007010\n",
              "18  0.0 -0.007010\n",
              "19  0.0 -0.007010\n",
              "20  0.0 -0.007010\n",
              "21  0.0 -0.007010\n",
              "22  0.0 -0.007010\n",
              "23  0.0 -0.007010\n",
              "24  0.0 -0.007010\n",
              "25  0.0 -0.007010\n",
              "26  0.0 -0.007010\n",
              "27  0.0 -0.007010\n",
              "28  0.0 -0.007010\n",
              "29  0.0 -0.007010\n",
              "30  0.0 -0.007010\n",
              "31  0.0 -0.007010\n",
              "32  0.0 -0.007010\n",
              "33  0.0 -0.007010\n",
              "34  0.0 -0.007010\n",
              "35  0.0 -0.007010\n",
              "36  0.0 -0.007010\n",
              "37  0.0 -0.007010\n",
              "38  0.0 -0.007010\n",
              "39  0.0 -0.007010\n",
              "40  0.0 -0.007010\n",
              "41  0.0 -0.007010\n",
              "42  0.0 -0.007010\n",
              "43  0.2 -0.007010\n",
              "44  0.0  0.165393\n",
              "45  0.0 -0.031376\n",
              "46  0.0  0.005150\n",
              "47  0.0 -0.004304\n",
              "48  0.0 -0.005246\n",
              "49  0.0 -0.005443\n",
              "50  0.0 -0.005471\n",
              "51  0.0 -0.007380\n",
              "52  0.0 -0.004927\n",
              "53  0.0 -0.007191\n",
              "54  0.0 -0.007010\n",
              "55  0.0 -0.007010\n",
              "56  0.0 -0.007010\n",
              "57  0.0 -0.007010\n",
              "58  0.0 -0.007010\n",
              "59  0.0 -0.007010\n",
              "60  0.0 -0.007010\n",
              "61  0.0 -0.007010\n",
              "62  0.0 -0.007010\n",
              "63  0.0 -0.007010\n",
              "64  0.0 -0.007010\n",
              "65  0.0 -0.007010\n",
              "66  0.0 -0.007010\n",
              "67  0.0 -0.007010\n",
              "68  0.0 -0.007010\n",
              "69  0.0 -0.007010\n",
              "70  0.0 -0.007010\n",
              "71  0.0 -0.007010\n",
              "72  0.0 -0.007010\n",
              "73  0.0 -0.007010\n",
              "74  0.0 -0.007010\n",
              "75  0.0 -0.007010\n",
              "76  0.0 -0.007010\n",
              "77  0.0 -0.007010\n",
              "78  0.0 -0.007010\n",
              "79  0.0 -0.007010\n",
              "80  0.0 -0.007010\n",
              "81  0.0 -0.007010\n",
              "82  0.0 -0.007010\n",
              "83  0.0 -0.007010\n",
              "84  0.0 -0.007010\n",
              "85  0.0 -0.007010\n",
              "86  0.0 -0.007010\n",
              "87  0.0 -0.007010\n",
              "88  0.0 -0.007010\n",
              "89  0.0 -0.007010\n",
              "90  0.0 -0.007010\n",
              "91  0.0 -0.007010\n",
              "92  0.0 -0.007010\n",
              "93  0.0 -0.007010\n",
              "94  0.0 -0.007010\n",
              "95  0.0 -0.007010\n",
              "96  0.0 -0.007010\n",
              "97  0.0 -0.007010\n",
              "98  0.0 -0.007010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "K0zeulqtWlVJ",
        "outputId": "446406f7-8ea3-41da-9263-5468a49db407"
      },
      "source": [
        "y_y_hat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.311304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5960</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5961</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5962</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5964</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.007010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5965 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        y     y_hat\n",
              "0     0.0  0.311304\n",
              "1     0.0  0.101148\n",
              "2     0.0  0.102440\n",
              "3     0.0  0.023606\n",
              "4     0.0  0.004690\n",
              "...   ...       ...\n",
              "5960  0.0 -0.007010\n",
              "5961  0.0 -0.007010\n",
              "5962  0.0 -0.007010\n",
              "5963  0.0 -0.007010\n",
              "5964  0.0 -0.007010\n",
              "\n",
              "[5965 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXcKBvs9T4rJ"
      },
      "source": [
        "y_y_hat['residual_error'] = y_y_hat['y'] - y_y_hat['y_hat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "jgglh9WaUQ0I",
        "outputId": "e8630021-70d1-403c-deaf-3021ceef6057"
      },
      "source": [
        "y_y_hat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5965.000000</td>\n",
              "      <td>5965.000000</td>\n",
              "      <td>5965.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.031182</td>\n",
              "      <td>0.017353</td>\n",
              "      <td>0.013829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.203481</td>\n",
              "      <td>0.124898</td>\n",
              "      <td>0.173362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.171421</td>\n",
              "      <td>-1.326600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.007010</td>\n",
              "      <td>0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.007010</td>\n",
              "      <td>0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.007010</td>\n",
              "      <td>0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.126600</td>\n",
              "      <td>8.483362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 y        y_hat  residual_error\n",
              "count  5965.000000  5965.000000     5965.000000\n",
              "mean      0.031182     0.017353        0.013829\n",
              "std       0.203481     0.124898        0.173362\n",
              "min       0.000000    -0.171421       -1.326600\n",
              "25%       0.000000    -0.007010        0.007010\n",
              "50%       0.000000    -0.007010        0.007010\n",
              "75%       0.000000    -0.007010        0.007010\n",
              "max       9.000000     2.126600        8.483362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "eLwfI3G_Upsd",
        "outputId": "e7f53db6-1af1-404d-b5d6-25fd895e524a"
      },
      "source": [
        "y_y_hat [abs(y_y_hat['residual_error'])>2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>4.6</td>\n",
              "      <td>0.165393</td>\n",
              "      <td>4.434607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.516637</td>\n",
              "      <td>8.483362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        y     y_hat  residual_error\n",
              "964   4.6  0.165393        4.434607\n",
              "1829  9.0  0.516637        8.483362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtv3coEMCwJw",
        "outputId": "da0c07d0-c129-416a-8aeb-38de5bdb3ab2"
      },
      "source": [
        "test = testY[: , 0]\n",
        "predictions = testPredict[:,0]\n",
        "mre_score = max_error (test, predictions)\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (test, predictions)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( test, predictions))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(test, predictions)\n",
        "print('Test R2: %.3f' % r2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 8.483\n",
            "Test MAE: 0.035\n",
            "Test RMSE: 0.174\n",
            "Test R2: 0.269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y7T29YwFNIn",
        "outputId": "3bb9011b-8e4e-4cbe-d274-cb9e32273da5"
      },
      "source": [
        "# Scores on rain and no rain tuples seperately \n",
        "\n",
        "results  = pd.DataFrame( { 'true' :test , 'prediction':predictions } )\n",
        "print (\"Scores on rain tuples \\n\")\n",
        "\n",
        "results_true_rain = results[results['true']!=0].true\n",
        "results_prediction_rain = results[results['true']!=0].prediction\n",
        "mre_score = max_error ( results_true_rain,results_prediction_rain )\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (results_true_rain, results_prediction_rain)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( results_true_rain, results_prediction_rain))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(results_true_rain, results_prediction_rain)\n",
        "print('Test R2: %.3f' % r2)\n",
        "\n",
        "\n",
        "print (\"\\n Scores on no-rain tuples \\n\")\n",
        "results_true_no_rain = results[results['true']==0].true\n",
        "results_prediction_no_rain = results[results['true']==0].prediction\n",
        "\n",
        "mre_score = max_error (results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test MRE: %.3f' % mre_score)\n",
        "mae_score = mean_absolute_error (results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test MAE: %.3f' % mae_score)\n",
        "rmse_score = np.sqrt(mean_squared_error( results_true_no_rain, results_prediction_no_rain))\n",
        "print('Test RMSE: %.3f' % rmse_score)\n",
        "r2 = r2_score(results_true_no_rain, results_prediction_no_rain)\n",
        "print('Test R2: %.3f' % r2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 8.642\n",
            "Test MAE: 0.449\n",
            "Test RMSE: 0.758\n",
            "Test R2: -0.311\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 1.170\n",
            "Test MAE: 0.094\n",
            "Test RMSE: 0.099\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "6tyTM13gl-_V",
        "outputId": "91cddf95-0e86-4f08-a855-8398e59ff63d"
      },
      "source": [
        "# Fit the model\n",
        "#history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-dfd230c420db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5WAw6zw9ffoc",
        "outputId": "5854a714-cb15-4987-9ef4-2b3b5c8eafe1"
      },
      "source": [
        "# shift train predictions for plotting\n",
        "\n",
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back] = trainPredict.reshape(( 1 , 13942))\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1] = testPredict.reshape(( 1 , 5974))\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset ) \n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeOWLg2CaHoU"
      },
      "source": [
        "15 min error analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJIdZB_YkuFT",
        "outputId": "5e093363-b97f-4b0a-a871-9035f6894e0e"
      },
      "source": [
        "evaluate_model( testY , test2Predict , testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 13.520\n",
            "Test MAE: 0.050\n",
            "Test RMSE: 0.268\n",
            "Test R2: -0.734\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 13.520\n",
            "Test MAE: 0.440\n",
            "Test RMSE: 1.083\n",
            "Test R2: -1.676\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 1.130\n",
            "Test MAE: 0.026\n",
            "Test RMSE: 0.050\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6AQXBLaKuW",
        "outputId": "de436fc5-83af-4dff-dbde-b0beac1573ae"
      },
      "source": [
        "evaluate_model( testY , test2Predict , testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 8.972\n",
            "Test MAE: 0.031\n",
            "Test RMSE: 0.201\n",
            "Test R2: 0.020\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 8.972\n",
            "Test MAE: 0.507\n",
            "Test RMSE: 0.828\n",
            "Test R2: -0.563\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 0.064\n",
            "Test MAE: 0.001\n",
            "Test RMSE: 0.003\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_wsZYlnhpiS",
        "outputId": "5b1092e9-3514-4fe4-f582-80f12f1a17f3"
      },
      "source": [
        "evaluate_model( testY , test2Predict , testY.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 13.520\n",
            "Test MAE: 0.050\n",
            "Test RMSE: 0.268\n",
            "Test R2: -0.734\n",
            "Scores on rain tuples \n",
            "\n",
            "Test MRE: 13.520\n",
            "Test MAE: 0.440\n",
            "Test RMSE: 1.083\n",
            "Test R2: -1.676\n",
            "\n",
            " Scores on no-rain tuples \n",
            "\n",
            "Test MRE: 1.130\n",
            "Test MAE: 0.026\n",
            "Test RMSE: 0.050\n",
            "Test R2: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpI_feEXaJDo",
        "outputId": "cc2e6d96-75e6-4261-b8df-a978ce833a11"
      },
      "source": [
        "max (testY )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5113636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHOu7_EwffsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de063d3-c232-4fd3-e6cc-acd3a2f114f5"
      },
      "source": [
        "max ( test2Predict) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8477283], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM-bY7Usew4u"
      },
      "source": [
        "testPredict =  scaler.inverse_transform(test2Predict.reshape((testY.shape[0],1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOIq2R1tjEz_",
        "outputId": "a2bf984e-bcec-4f87-e374-8f17387c084b"
      },
      "source": [
        "max ( testPredict )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.920019], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7UkGvZVjKMD"
      },
      "source": [
        "testY2 =  scaler.inverse_transform(testY.reshape((testY.shape[0],1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVJU16S6jYIS",
        "outputId": "fe61aa01-aeb4-43a7-f584-83bef1b51977"
      },
      "source": [
        "max (testY2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-u9uhzmkDNs",
        "outputId": "ff7b891d-dbf1-4872-e06a-d4b17b11e156"
      },
      "source": [
        "testPredict.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5965, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-FhXadokHzq",
        "outputId": "a882d52b-3034-43f0-c443-56b243f6a028"
      },
      "source": [
        "testY2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5965, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGt6twpball"
      },
      "source": [
        "#Analysis of performance on Test data \n",
        "y = testY2[: , 0 ]\n",
        "y_hat = testPredict[:,0 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSzi69uvbm_9",
        "outputId": "e287a9dc-bd2a-43a3-bb83-d5901e2a6122"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8dMdkoMbamC"
      },
      "source": [
        "y_y_hat = pd.DataFrame({'y':y , 'y_hat':y_hat}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYhbh37bamC"
      },
      "source": [
        "pd.set_option('display.max_rows', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oGGJ8gcffyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "002cc1e3-3668-4d50-d785-97194498ee27"
      },
      "source": [
        "y_y_hat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5960</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5961</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5962</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5964</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5965 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        y     y_hat\n",
              "0     0.0  0.013545\n",
              "1     0.0  0.002360\n",
              "2     0.0  0.002200\n",
              "3     0.0  0.006785\n",
              "4     0.0  0.008326\n",
              "...   ...       ...\n",
              "5960  0.0  0.020495\n",
              "5961  0.0  0.020495\n",
              "5962  0.0  0.020495\n",
              "5963  0.0  0.020495\n",
              "5964  0.0  0.020495\n",
              "\n",
              "[5965 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SExXy8QkbxLn"
      },
      "source": [
        "y_y_hat['residual_error'] = y_y_hat['y'] - y_y_hat['y_hat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "brjZmEq5c1hQ",
        "outputId": "75293b2f-74d1-471c-a90f-68359ddefa26"
      },
      "source": [
        "y_y_hat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5965.000000</td>\n",
              "      <td>5965.000000</td>\n",
              "      <td>5965.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.031182</td>\n",
              "      <td>0.045937</td>\n",
              "      <td>-0.014756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.203481</td>\n",
              "      <td>0.250989</td>\n",
              "      <td>0.267514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-13.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.920019</td>\n",
              "      <td>8.505400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 y        y_hat  residual_error\n",
              "count  5965.000000  5965.000000     5965.000000\n",
              "mean      0.031182     0.045937       -0.014756\n",
              "std       0.203481     0.250989        0.267514\n",
              "min       0.000000     0.000615      -13.520020\n",
              "25%       0.000000     0.020495       -0.020495\n",
              "50%       0.000000     0.020495       -0.020495\n",
              "75%       0.000000     0.020495       -0.020495\n",
              "max       9.000000    14.920019        8.505400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiMWae1SkeDk"
      },
      "source": [
        "#More analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bhsktLkb82D"
      },
      "source": [
        "trainorig, testorig = dataset[0:train_size], dataset[train_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKgnt7_EjpOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8149a111-9363-4fb2-e1f7-1a4845706e06"
      },
      "source": [
        "max(testorig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydX1RfAwkhGe",
        "outputId": "6471fb53-c653-4d44-b5f5-e2b7fccb76f2"
      },
      "source": [
        "  mre_score = max_error (y_y_hat['y'], y_y_hat['y_hat'])\n",
        "  print('Test MRE: %.3f' % mre_score) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MRE: 13.520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "rY91SQcWlB5_",
        "outputId": "34fa1599-a146-4a49-c335-a69b807caaf2"
      },
      "source": [
        "y_y_hat [abs(y_y_hat['residual_error'])>2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>1.4</td>\n",
              "      <td>14.920019</td>\n",
              "      <td>-13.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>0.2</td>\n",
              "      <td>6.349534</td>\n",
              "      <td>-6.149534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>4.6</td>\n",
              "      <td>0.065254</td>\n",
              "      <td>4.534746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.494600</td>\n",
              "      <td>8.505400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1830</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.643912</td>\n",
              "      <td>-4.643912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4244</th>\n",
              "      <td>2.2</td>\n",
              "      <td>0.177111</td>\n",
              "      <td>2.022889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        y      y_hat  residual_error\n",
              "533   1.4  14.920019      -13.520020\n",
              "540   0.2   6.349534       -6.149534\n",
              "964   4.6   0.065254        4.534746\n",
              "1829  9.0   0.494600        8.505400\n",
              "1830  1.0   5.643912       -4.643912\n",
              "4244  2.2   0.177111        2.022889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gy_UWGr-l3z7",
        "outputId": "f8f048f2-7e8a-4b72-d764-5f9da79729da"
      },
      "source": [
        "y_y_hat[500:590] #533 540"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.579505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.376687</td>\n",
              "      <td>0.023313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.497714</td>\n",
              "      <td>0.102286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.425366</td>\n",
              "      <td>-0.025366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.413368</td>\n",
              "      <td>0.386632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.994715</td>\n",
              "      <td>-0.394715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.368689</td>\n",
              "      <td>0.431311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.559832</td>\n",
              "      <td>1.440168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.342064</td>\n",
              "      <td>-0.342064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.832136</td>\n",
              "      <td>0.767864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.180858</td>\n",
              "      <td>-0.980859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.033012</td>\n",
              "      <td>1.966988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>1.4</td>\n",
              "      <td>14.920019</td>\n",
              "      <td>-13.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>2.4</td>\n",
              "      <td>0.658514</td>\n",
              "      <td>1.741486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>2.4</td>\n",
              "      <td>1.468253</td>\n",
              "      <td>0.931747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>0.8</td>\n",
              "      <td>1.182527</td>\n",
              "      <td>-0.382527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.330607</td>\n",
              "      <td>0.269393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.131160</td>\n",
              "      <td>0.268840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.108078</td>\n",
              "      <td>1.091922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>0.2</td>\n",
              "      <td>6.349534</td>\n",
              "      <td>-6.149534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>-0.007038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003824</td>\n",
              "      <td>-0.003824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>-0.002104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004056</td>\n",
              "      <td>-0.004056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008092</td>\n",
              "      <td>0.191908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038131</td>\n",
              "      <td>-0.038131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028285</td>\n",
              "      <td>-0.028285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021356</td>\n",
              "      <td>-0.021356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021532</td>\n",
              "      <td>-0.021532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>-0.021848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020639</td>\n",
              "      <td>-0.020639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020509</td>\n",
              "      <td>-0.020509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>0.179717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064357</td>\n",
              "      <td>-0.064357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043055</td>\n",
              "      <td>-0.043055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031684</td>\n",
              "      <td>-0.031684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025608</td>\n",
              "      <td>-0.025608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022247</td>\n",
              "      <td>-0.022247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020639</td>\n",
              "      <td>-0.020639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020509</td>\n",
              "      <td>-0.020509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>-0.020283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020180</td>\n",
              "      <td>-0.020180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020166</td>\n",
              "      <td>-0.020166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       y      y_hat  residual_error\n",
              "500  0.0   0.020495       -0.020495\n",
              "501  0.0   0.020495       -0.020495\n",
              "502  0.0   0.020495       -0.020495\n",
              "503  0.0   0.020495       -0.020495\n",
              "504  0.0   0.020495       -0.020495\n",
              "505  0.0   0.020495       -0.020495\n",
              "506  0.0   0.020495       -0.020495\n",
              "507  0.0   0.020495       -0.020495\n",
              "508  0.0   0.020495       -0.020495\n",
              "509  0.0   0.020495       -0.020495\n",
              "510  0.0   0.020495       -0.020495\n",
              "511  0.0   0.020495       -0.020495\n",
              "512  0.0   0.020495       -0.020495\n",
              "513  0.0   0.020495       -0.020495\n",
              "514  0.0   0.020495       -0.020495\n",
              "515  0.0   0.020495       -0.020495\n",
              "516  0.0   0.020495       -0.020495\n",
              "517  0.0   0.020495       -0.020495\n",
              "518  0.0   0.020495       -0.020495\n",
              "519  0.0   0.020495       -0.020495\n",
              "520  0.0   0.020495       -0.020495\n",
              "521  0.6   0.020495        0.579505\n",
              "522  0.4   0.376687        0.023313\n",
              "523  0.6   0.497714        0.102286\n",
              "524  0.4   0.425366       -0.025366\n",
              "525  0.8   0.413368        0.386632\n",
              "526  0.6   0.994715       -0.394715\n",
              "527  0.8   0.368689        0.431311\n",
              "528  2.0   0.559832        1.440168\n",
              "529  1.0   1.342064       -0.342064\n",
              "530  1.6   0.832136        0.767864\n",
              "531  0.2   1.180858       -0.980859\n",
              "532  2.0   0.033012        1.966988\n",
              "533  1.4  14.920019      -13.520020\n",
              "534  2.4   0.658514        1.741486\n",
              "535  2.4   1.468253        0.931747\n",
              "536  0.8   1.182527       -0.382527\n",
              "537  0.6   0.330607        0.269393\n",
              "538  0.4   0.131160        0.268840\n",
              "539  1.2   0.108078        1.091922\n",
              "540  0.2   6.349534       -6.149534\n",
              "541  0.0   0.007038       -0.007038\n",
              "542  0.0   0.003824       -0.003824\n",
              "543  0.0   0.002104       -0.002104\n",
              "544  0.0   0.004056       -0.004056\n",
              "545  0.2   0.008092        0.191908\n",
              "546  0.0   0.038131       -0.038131\n",
              "547  0.0   0.028285       -0.028285\n",
              "548  0.0   0.021356       -0.021356\n",
              "549  0.0   0.021532       -0.021532\n",
              "550  0.0   0.021848       -0.021848\n",
              "551  0.0   0.020639       -0.020639\n",
              "552  0.0   0.020509       -0.020509\n",
              "553  0.2   0.020283        0.179717\n",
              "554  0.0   0.064357       -0.064357\n",
              "555  0.0   0.043055       -0.043055\n",
              "556  0.0   0.031684       -0.031684\n",
              "557  0.0   0.025608       -0.025608\n",
              "558  0.0   0.022247       -0.022247\n",
              "559  0.0   0.020639       -0.020639\n",
              "560  0.0   0.020509       -0.020509\n",
              "561  0.0   0.020283       -0.020283\n",
              "562  0.0   0.020180       -0.020180\n",
              "563  0.0   0.020166       -0.020166\n",
              "564  0.0   0.020495       -0.020495\n",
              "565  0.0   0.020495       -0.020495\n",
              "566  0.0   0.020495       -0.020495\n",
              "567  0.0   0.020495       -0.020495\n",
              "568  0.0   0.020495       -0.020495\n",
              "569  0.0   0.020495       -0.020495\n",
              "570  0.0   0.020495       -0.020495\n",
              "571  0.0   0.020495       -0.020495\n",
              "572  0.0   0.020495       -0.020495\n",
              "573  0.0   0.020495       -0.020495\n",
              "574  0.0   0.020495       -0.020495\n",
              "575  0.0   0.020495       -0.020495\n",
              "576  0.0   0.020495       -0.020495\n",
              "577  0.0   0.020495       -0.020495\n",
              "578  0.0   0.020495       -0.020495\n",
              "579  0.0   0.020495       -0.020495\n",
              "580  0.0   0.020495       -0.020495\n",
              "581  0.0   0.020495       -0.020495\n",
              "582  0.0   0.020495       -0.020495\n",
              "583  0.0   0.020495       -0.020495\n",
              "584  0.0   0.020495       -0.020495\n",
              "585  0.0   0.020495       -0.020495\n",
              "586  0.0   0.020495       -0.020495\n",
              "587  0.0   0.020495       -0.020495\n",
              "588  0.0   0.020495       -0.020495\n",
              "589  0.0   0.020495       -0.020495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLZAQdObmzmM",
        "outputId": "708eb4a0-da11-4b21-e78d-65376c97efdd"
      },
      "source": [
        "y_y_hat[950:1000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.179505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>4.6</td>\n",
              "      <td>0.065254</td>\n",
              "      <td>4.534746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>965</th>\n",
              "      <td>0.8</td>\n",
              "      <td>1.586515</td>\n",
              "      <td>-0.786515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>966</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.306331</td>\n",
              "      <td>0.293669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848983</td>\n",
              "      <td>-0.848983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.012616</td>\n",
              "      <td>0.187384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.093244</td>\n",
              "      <td>0.106756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.598461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.061602</td>\n",
              "      <td>0.138398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112382</td>\n",
              "      <td>-0.112382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057863</td>\n",
              "      <td>-0.057863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030830</td>\n",
              "      <td>-0.030830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.025277</td>\n",
              "      <td>0.174723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068030</td>\n",
              "      <td>-0.068030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040472</td>\n",
              "      <td>-0.040472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027114</td>\n",
              "      <td>-0.027114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020883</td>\n",
              "      <td>-0.020883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019688</td>\n",
              "      <td>-0.019688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020299</td>\n",
              "      <td>-0.020299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020509</td>\n",
              "      <td>-0.020509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>-0.020283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020180</td>\n",
              "      <td>-0.020180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020166</td>\n",
              "      <td>-0.020166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       y     y_hat  residual_error\n",
              "950  0.0  0.020495       -0.020495\n",
              "951  0.0  0.020495       -0.020495\n",
              "952  0.0  0.020495       -0.020495\n",
              "953  0.0  0.020495       -0.020495\n",
              "954  0.0  0.020495       -0.020495\n",
              "955  0.0  0.020495       -0.020495\n",
              "956  0.0  0.020495       -0.020495\n",
              "957  0.0  0.020495       -0.020495\n",
              "958  0.0  0.020495       -0.020495\n",
              "959  0.0  0.020495       -0.020495\n",
              "960  0.0  0.020495       -0.020495\n",
              "961  0.0  0.020495       -0.020495\n",
              "962  0.0  0.020495       -0.020495\n",
              "963  0.2  0.020495        0.179505\n",
              "964  4.6  0.065254        4.534746\n",
              "965  0.8  1.586515       -0.786515\n",
              "966  0.6  0.306331        0.293669\n",
              "967  0.0  0.848983       -0.848983\n",
              "968  0.2  0.012616        0.187384\n",
              "969  0.2  0.093244        0.106756\n",
              "970  0.6  0.001539        0.598461\n",
              "971  0.2  0.061602        0.138398\n",
              "972  0.0  0.112382       -0.112382\n",
              "973  0.0  0.057863       -0.057863\n",
              "974  0.0  0.030830       -0.030830\n",
              "975  0.2  0.025277        0.174723\n",
              "976  0.0  0.068030       -0.068030\n",
              "977  0.0  0.040472       -0.040472\n",
              "978  0.0  0.027114       -0.027114\n",
              "979  0.0  0.020883       -0.020883\n",
              "980  0.0  0.019688       -0.019688\n",
              "981  0.0  0.020299       -0.020299\n",
              "982  0.0  0.020509       -0.020509\n",
              "983  0.0  0.020283       -0.020283\n",
              "984  0.0  0.020180       -0.020180\n",
              "985  0.0  0.020166       -0.020166\n",
              "986  0.0  0.020495       -0.020495\n",
              "987  0.0  0.020495       -0.020495\n",
              "988  0.0  0.020495       -0.020495\n",
              "989  0.0  0.020495       -0.020495\n",
              "990  0.0  0.020495       -0.020495\n",
              "991  0.0  0.020495       -0.020495\n",
              "992  0.0  0.020495       -0.020495\n",
              "993  0.0  0.020495       -0.020495\n",
              "994  0.0  0.020495       -0.020495\n",
              "995  0.0  0.020495       -0.020495\n",
              "996  0.0  0.020495       -0.020495\n",
              "997  0.0  0.020495       -0.020495\n",
              "998  0.0  0.020495       -0.020495\n",
              "999  0.0  0.020495       -0.020495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YG_d-IN9n8gz",
        "outputId": "796beae6-d03e-4df6-b896-3e597ec3747a"
      },
      "source": [
        "y_y_hat[1800:1850]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1800</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1803</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1804</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1807</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1808</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1809</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1810</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1811</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1812</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1813</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1814</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1815</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1823</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1824</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1825</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.779505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.630332</td>\n",
              "      <td>-0.430332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.421713</td>\n",
              "      <td>0.178287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.494600</td>\n",
              "      <td>8.505400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1830</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.643912</td>\n",
              "      <td>-4.643912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1831</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.966490</td>\n",
              "      <td>-0.566490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1832</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.452509</td>\n",
              "      <td>-0.452509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1833</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008667</td>\n",
              "      <td>-0.008667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1834</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053172</td>\n",
              "      <td>-0.053172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1835</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134337</td>\n",
              "      <td>-0.134337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1836</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>-0.001122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.002629</td>\n",
              "      <td>0.197371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1838</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.021109</td>\n",
              "      <td>0.178891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157710</td>\n",
              "      <td>-0.157710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.060171</td>\n",
              "      <td>0.339829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.296797</td>\n",
              "      <td>-0.096797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264253</td>\n",
              "      <td>-0.264253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.093589</td>\n",
              "      <td>0.106411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159352</td>\n",
              "      <td>-0.159352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.069018</td>\n",
              "      <td>0.530982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.517152</td>\n",
              "      <td>-0.317152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.346624</td>\n",
              "      <td>1.253376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1848</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.039768</td>\n",
              "      <td>1.960232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1849</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.637982</td>\n",
              "      <td>0.162018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        y     y_hat  residual_error\n",
              "1800  0.0  0.020495       -0.020495\n",
              "1801  0.0  0.020495       -0.020495\n",
              "1802  0.0  0.020495       -0.020495\n",
              "1803  0.0  0.020495       -0.020495\n",
              "1804  0.0  0.020495       -0.020495\n",
              "1805  0.0  0.020495       -0.020495\n",
              "1806  0.0  0.020495       -0.020495\n",
              "1807  0.0  0.020495       -0.020495\n",
              "1808  0.0  0.020495       -0.020495\n",
              "1809  0.0  0.020495       -0.020495\n",
              "1810  0.0  0.020495       -0.020495\n",
              "1811  0.0  0.020495       -0.020495\n",
              "1812  0.0  0.020495       -0.020495\n",
              "1813  0.0  0.020495       -0.020495\n",
              "1814  0.0  0.020495       -0.020495\n",
              "1815  0.0  0.020495       -0.020495\n",
              "1816  0.0  0.020495       -0.020495\n",
              "1817  0.0  0.020495       -0.020495\n",
              "1818  0.0  0.020495       -0.020495\n",
              "1819  0.0  0.020495       -0.020495\n",
              "1820  0.0  0.020495       -0.020495\n",
              "1821  0.0  0.020495       -0.020495\n",
              "1822  0.0  0.020495       -0.020495\n",
              "1823  0.0  0.020495       -0.020495\n",
              "1824  0.0  0.020495       -0.020495\n",
              "1825  0.0  0.020495       -0.020495\n",
              "1826  0.8  0.020495        0.779505\n",
              "1827  0.2  0.630332       -0.430332\n",
              "1828  0.6  0.421713        0.178287\n",
              "1829  9.0  0.494600        8.505400\n",
              "1830  1.0  5.643912       -4.643912\n",
              "1831  0.4  0.966490       -0.566490\n",
              "1832  0.0  0.452509       -0.452509\n",
              "1833  0.0  0.008667       -0.008667\n",
              "1834  0.0  0.053172       -0.053172\n",
              "1835  0.0  0.134337       -0.134337\n",
              "1836  0.0  0.001122       -0.001122\n",
              "1837  0.2  0.002629        0.197371\n",
              "1838  0.2  0.021109        0.178891\n",
              "1839  0.0  0.157710       -0.157710\n",
              "1840  0.4  0.060171        0.339829\n",
              "1841  0.2  0.296797       -0.096797\n",
              "1842  0.0  0.264253       -0.264253\n",
              "1843  0.2  0.093589        0.106411\n",
              "1844  0.0  0.159352       -0.159352\n",
              "1845  0.6  0.069018        0.530982\n",
              "1846  0.2  0.517152       -0.317152\n",
              "1847  1.6  0.346624        1.253376\n",
              "1848  3.0  1.039768        1.960232\n",
              "1849  0.8  0.637982        0.162018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HlVhnk8uo4Sa",
        "outputId": "e248bb6a-7eb7-447e-fe5a-53b31ed3dce7"
      },
      "source": [
        "y_y_hat[4200:4280] #4244\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>residual_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4200</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4201</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4202</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4203</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4204</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4205</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4206</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4207</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4208</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4209</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4210</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4211</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4212</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4213</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4214</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4215</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4217</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4218</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4219</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4220</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4221</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4222</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4223</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4224</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4225</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4226</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4227</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4228</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4229</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4230</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4231</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4232</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4233</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4234</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4235</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4236</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4237</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4238</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4240</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4241</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4242</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4243</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.379505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4244</th>\n",
              "      <td>2.2</td>\n",
              "      <td>0.177111</td>\n",
              "      <td>2.022889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4245</th>\n",
              "      <td>1.2</td>\n",
              "      <td>1.386637</td>\n",
              "      <td>-0.186637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4246</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.315980</td>\n",
              "      <td>-0.115980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4247</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.382808</td>\n",
              "      <td>-0.382808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4248</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008370</td>\n",
              "      <td>0.191630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076944</td>\n",
              "      <td>-0.076944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4250</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-0.000615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4251</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003055</td>\n",
              "      <td>-0.003055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4252</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.006576</td>\n",
              "      <td>0.193424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4253</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.036755</td>\n",
              "      <td>0.363245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4254</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.231991</td>\n",
              "      <td>0.368009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4255</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.762553</td>\n",
              "      <td>-0.562553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4256</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.237611</td>\n",
              "      <td>-0.037611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4257</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.244938</td>\n",
              "      <td>-0.244938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4258</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041109</td>\n",
              "      <td>-0.041109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4259</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030861</td>\n",
              "      <td>-0.030861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4260</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029026</td>\n",
              "      <td>-0.029026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4261</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020471</td>\n",
              "      <td>-0.020471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4262</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017433</td>\n",
              "      <td>-0.017433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4263</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017163</td>\n",
              "      <td>-0.017163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4264</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018388</td>\n",
              "      <td>-0.018388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019514</td>\n",
              "      <td>-0.019514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4266</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020166</td>\n",
              "      <td>-0.020166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4267</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4268</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4269</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4270</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>-0.020495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4272</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.179505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4273</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065254</td>\n",
              "      <td>-0.065254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4274</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043236</td>\n",
              "      <td>-0.043236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4275</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031684</td>\n",
              "      <td>-0.031684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025608</td>\n",
              "      <td>-0.025608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4277</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022247</td>\n",
              "      <td>-0.022247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4278</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020639</td>\n",
              "      <td>-0.020639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4279</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020509</td>\n",
              "      <td>-0.020509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        y     y_hat  residual_error\n",
              "4200  0.0  0.020495       -0.020495\n",
              "4201  0.0  0.020495       -0.020495\n",
              "4202  0.0  0.020495       -0.020495\n",
              "4203  0.0  0.020495       -0.020495\n",
              "4204  0.0  0.020495       -0.020495\n",
              "4205  0.0  0.020495       -0.020495\n",
              "4206  0.0  0.020495       -0.020495\n",
              "4207  0.0  0.020495       -0.020495\n",
              "4208  0.0  0.020495       -0.020495\n",
              "4209  0.0  0.020495       -0.020495\n",
              "4210  0.0  0.020495       -0.020495\n",
              "4211  0.0  0.020495       -0.020495\n",
              "4212  0.0  0.020495       -0.020495\n",
              "4213  0.0  0.020495       -0.020495\n",
              "4214  0.0  0.020495       -0.020495\n",
              "4215  0.0  0.020495       -0.020495\n",
              "4216  0.0  0.020495       -0.020495\n",
              "4217  0.0  0.020495       -0.020495\n",
              "4218  0.0  0.020495       -0.020495\n",
              "4219  0.0  0.020495       -0.020495\n",
              "4220  0.0  0.020495       -0.020495\n",
              "4221  0.0  0.020495       -0.020495\n",
              "4222  0.0  0.020495       -0.020495\n",
              "4223  0.0  0.020495       -0.020495\n",
              "4224  0.0  0.020495       -0.020495\n",
              "4225  0.0  0.020495       -0.020495\n",
              "4226  0.0  0.020495       -0.020495\n",
              "4227  0.0  0.020495       -0.020495\n",
              "4228  0.0  0.020495       -0.020495\n",
              "4229  0.0  0.020495       -0.020495\n",
              "4230  0.0  0.020495       -0.020495\n",
              "4231  0.0  0.020495       -0.020495\n",
              "4232  0.0  0.020495       -0.020495\n",
              "4233  0.0  0.020495       -0.020495\n",
              "4234  0.0  0.020495       -0.020495\n",
              "4235  0.0  0.020495       -0.020495\n",
              "4236  0.0  0.020495       -0.020495\n",
              "4237  0.0  0.020495       -0.020495\n",
              "4238  0.0  0.020495       -0.020495\n",
              "4239  0.0  0.020495       -0.020495\n",
              "4240  0.0  0.020495       -0.020495\n",
              "4241  0.0  0.020495       -0.020495\n",
              "4242  0.0  0.020495       -0.020495\n",
              "4243  0.4  0.020495        0.379505\n",
              "4244  2.2  0.177111        2.022889\n",
              "4245  1.2  1.386637       -0.186637\n",
              "4246  0.2  0.315980       -0.115980\n",
              "4247  0.0  0.382808       -0.382808\n",
              "4248  0.2  0.008370        0.191630\n",
              "4249  0.0  0.076944       -0.076944\n",
              "4250  0.0  0.000615       -0.000615\n",
              "4251  0.0  0.003055       -0.003055\n",
              "4252  0.2  0.006576        0.193424\n",
              "4253  0.4  0.036755        0.363245\n",
              "4254  0.6  0.231991        0.368009\n",
              "4255  0.2  0.762553       -0.562553\n",
              "4256  0.2  0.237611       -0.037611\n",
              "4257  0.0  0.244938       -0.244938\n",
              "4258  0.0  0.041109       -0.041109\n",
              "4259  0.0  0.030861       -0.030861\n",
              "4260  0.0  0.029026       -0.029026\n",
              "4261  0.0  0.020471       -0.020471\n",
              "4262  0.0  0.017433       -0.017433\n",
              "4263  0.0  0.017163       -0.017163\n",
              "4264  0.0  0.018388       -0.018388\n",
              "4265  0.0  0.019514       -0.019514\n",
              "4266  0.0  0.020166       -0.020166\n",
              "4267  0.0  0.020495       -0.020495\n",
              "4268  0.0  0.020495       -0.020495\n",
              "4269  0.0  0.020495       -0.020495\n",
              "4270  0.0  0.020495       -0.020495\n",
              "4271  0.0  0.020495       -0.020495\n",
              "4272  0.2  0.020495        0.179505\n",
              "4273  0.0  0.065254       -0.065254\n",
              "4274  0.0  0.043236       -0.043236\n",
              "4275  0.0  0.031684       -0.031684\n",
              "4276  0.0  0.025608       -0.025608\n",
              "4277  0.0  0.022247       -0.022247\n",
              "4278  0.0  0.020639       -0.020639\n",
              "4279  0.0  0.020509       -0.020509"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeRC5PjRpTD1",
        "outputId": "f542d162-b4a6-43e4-82bf-16170853282d"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbSnZwtAUJEW",
        "outputId": "5a9791ad-fca0-4757-9ca8-68b6225060f3"
      },
      "source": [
        "import tensorflow as tf \n",
        "print(tf. __version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuEnnB-pUXAi",
        "outputId": "df2d0954-b9da-406c-8649-2e27f427f924"
      },
      "source": [
        "import keras\n",
        "print(keras. __version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuSuSWUpUhb_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}